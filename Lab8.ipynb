{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0            08906 Adam Avenue\\nPort Victoria, MN 71782\n",
      "1              0926 Baird Roads, West Natalie, WV 81710\n",
      "2              9716 Samuel Ports\\nSouth Angel, NC 85005\n",
      "3       53805 Mandy Curve\\nSouth Courtneyport, IL 77108\n",
      "4        14815 Kevin Plains\\nNorth Andremouth, WV 60941\n",
      "5     58259 Brandon Street Suite 057\\nEast Kellyburg...\n",
      "6            988 Debbie Viaduct\\nBrittneybury, NJ 79538\n",
      "7               09249 Vincent Wall\\nEast Erin, NE 99317\n",
      "8            7270 Hernandez Plain\\nBowersview, GA 04552\n",
      "9     304 Stephanie Trafficway Suite 451\\nSouth Karl...\n",
      "10    4000 Wendy Bridge Suite 220\\nSouth Tammie, SC ...\n",
      "11            86552 Andre Island\\nJeffreyfort, CT 30674\n",
      "12            7580 Fields Fort\\nMitchellburgh, KS 68457\n",
      "13        688 Hubbard Gardens\\nWashingtonberg, CO 35383\n",
      "14    889 Angela Radial Suite 285\\nPort Joseph, ME 6...\n",
      "15      763 Brennan Lodge Apt. 451, Kevinberg, FL 91818\n",
      "16            307 Matthew Plaza\\nNorth Trevor, DE 40093\n",
      "17               278 Harris Shoal\\nSouth John, LA 54411\n",
      "18         834 Rachel Station\\nJessicaborough, NE 35501\n",
      "19                 1595 Julie Court\\nDunntown, AR 65311\n",
      "Name: mailing_address, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "url = 'https://github.com/esnt/Data/raw/main/MessyData/employeedata.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "print(df['mailing_address'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['first_name', 'last_name']] = df['name'].loc[df['name'].str.split().str.len() == 2].str.split(expand = True)\n",
    "df['area_code'] = df['phone_number'].str.extract(r'(\\d{3})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['birthyear'] = '19' + df['birthdate'].str[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a DataFrame named df with a 'height' column\n",
    "df['ht_in'] = (\n",
    "    df['height']\n",
    "    .str.split(\"'\")\n",
    "    .apply(lambda x: int(x[0]) * 12 + int(x[1].strip('\"')))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>phone_number</th>\n",
       "      <th>email_address</th>\n",
       "      <th>birthdate</th>\n",
       "      <th>startdate</th>\n",
       "      <th>mailing_address</th>\n",
       "      <th>job</th>\n",
       "      <th>height</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>area_code</th>\n",
       "      <th>birthyear</th>\n",
       "      <th>ht_in</th>\n",
       "      <th>domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ryan Wilkins</td>\n",
       "      <td>851-082-4165</td>\n",
       "      <td>vasquezdawn@hotmail.com</td>\n",
       "      <td>2/19/59</td>\n",
       "      <td>11/11/07</td>\n",
       "      <td>08906 Adam Avenue\\nPort Victoria, MN 71782</td>\n",
       "      <td>Teacher, special educational needs</td>\n",
       "      <td>6'2\"</td>\n",
       "      <td>Ryan</td>\n",
       "      <td>Wilkins</td>\n",
       "      <td>851</td>\n",
       "      <td>1959</td>\n",
       "      <td>74</td>\n",
       "      <td>hotmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sierra Turner</td>\n",
       "      <td>380-360-2156</td>\n",
       "      <td>carloswoods@noble.biz</td>\n",
       "      <td>10/5/51</td>\n",
       "      <td>1/12/02</td>\n",
       "      <td>0926 Baird Roads, West Natalie, WV 81710</td>\n",
       "      <td>Professor Emeritus</td>\n",
       "      <td>6'1\"</td>\n",
       "      <td>Sierra</td>\n",
       "      <td>Turner</td>\n",
       "      <td>380</td>\n",
       "      <td>1951</td>\n",
       "      <td>73</td>\n",
       "      <td>noble.biz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lydia Wood</td>\n",
       "      <td>(460)079-6057x24612</td>\n",
       "      <td>ryan36@baker-brown.com</td>\n",
       "      <td>8/8/43</td>\n",
       "      <td>2/27/10</td>\n",
       "      <td>9716 Samuel Ports\\nSouth Angel, NC 85005</td>\n",
       "      <td>Sports coach</td>\n",
       "      <td>5'4\"</td>\n",
       "      <td>Lydia</td>\n",
       "      <td>Wood</td>\n",
       "      <td>460</td>\n",
       "      <td>1943</td>\n",
       "      <td>64</td>\n",
       "      <td>baker-brown.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sherri Smith</td>\n",
       "      <td>171-311-9706x8273</td>\n",
       "      <td>patriciajohnson@vega.com</td>\n",
       "      <td>4/9/71</td>\n",
       "      <td>12/2/21</td>\n",
       "      <td>53805 Mandy Curve\\nSouth Courtneyport, IL 77108</td>\n",
       "      <td>Glass blower/designer</td>\n",
       "      <td>5'9\"</td>\n",
       "      <td>Sherri</td>\n",
       "      <td>Smith</td>\n",
       "      <td>171</td>\n",
       "      <td>1971</td>\n",
       "      <td>69</td>\n",
       "      <td>vega.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jeremy Owens</td>\n",
       "      <td>508-429-8841</td>\n",
       "      <td>marissasmith_@hotmail.com</td>\n",
       "      <td>8/12/56</td>\n",
       "      <td>4/17/02</td>\n",
       "      <td>14815 Kevin Plains\\nNorth Andremouth, WV 60941</td>\n",
       "      <td>Production assistant, television</td>\n",
       "      <td>5'0\"</td>\n",
       "      <td>Jeremy</td>\n",
       "      <td>Owens</td>\n",
       "      <td>508</td>\n",
       "      <td>1956</td>\n",
       "      <td>60</td>\n",
       "      <td>hotmail.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name         phone_number              email_address birthdate  \\\n",
       "0   Ryan Wilkins         851-082-4165    vasquezdawn@hotmail.com   2/19/59   \n",
       "1  Sierra Turner         380-360-2156      carloswoods@noble.biz   10/5/51   \n",
       "2     Lydia Wood  (460)079-6057x24612     ryan36@baker-brown.com    8/8/43   \n",
       "3   Sherri Smith    171-311-9706x8273   patriciajohnson@vega.com    4/9/71   \n",
       "4   Jeremy Owens         508-429-8841  marissasmith_@hotmail.com   8/12/56   \n",
       "\n",
       "  startdate                                  mailing_address  \\\n",
       "0  11/11/07       08906 Adam Avenue\\nPort Victoria, MN 71782   \n",
       "1   1/12/02         0926 Baird Roads, West Natalie, WV 81710   \n",
       "2   2/27/10         9716 Samuel Ports\\nSouth Angel, NC 85005   \n",
       "3   12/2/21  53805 Mandy Curve\\nSouth Courtneyport, IL 77108   \n",
       "4   4/17/02   14815 Kevin Plains\\nNorth Andremouth, WV 60941   \n",
       "\n",
       "                                  job height first_name last_name area_code  \\\n",
       "0  Teacher, special educational needs   6'2\"       Ryan   Wilkins       851   \n",
       "1                  Professor Emeritus   6'1\"     Sierra    Turner       380   \n",
       "2                        Sports coach   5'4\"      Lydia      Wood       460   \n",
       "3               Glass blower/designer   5'9\"     Sherri     Smith       171   \n",
       "4    Production assistant, television   5'0\"     Jeremy     Owens       508   \n",
       "\n",
       "  birthyear  ht_in           domain  \n",
       "0      1959     74      hotmail.com  \n",
       "1      1951     73        noble.biz  \n",
       "2      1943     64  baker-brown.com  \n",
       "3      1971     69         vega.com  \n",
       "4      1956     60      hotmail.com  "
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['domain'] = df['email_address'].str.extract(r'@(.+)$')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>phone_number</th>\n",
       "      <th>email_address</th>\n",
       "      <th>birthdate</th>\n",
       "      <th>startdate</th>\n",
       "      <th>mailing_address</th>\n",
       "      <th>job</th>\n",
       "      <th>height</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>area_code</th>\n",
       "      <th>birthyear</th>\n",
       "      <th>ht_in</th>\n",
       "      <th>domain</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ryan Wilkins</td>\n",
       "      <td>851-082-4165</td>\n",
       "      <td>vasquezdawn@hotmail.com</td>\n",
       "      <td>2059-02-19</td>\n",
       "      <td>2007-11-11</td>\n",
       "      <td>08906 Adam Avenue\\nPort Victoria, MN 71782</td>\n",
       "      <td>Teacher, special educational needs</td>\n",
       "      <td>6'2\"</td>\n",
       "      <td>Ryan</td>\n",
       "      <td>Wilkins</td>\n",
       "      <td>851</td>\n",
       "      <td>1959</td>\n",
       "      <td>74</td>\n",
       "      <td>hotmail.com</td>\n",
       "      <td>-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sierra Turner</td>\n",
       "      <td>380-360-2156</td>\n",
       "      <td>carloswoods@noble.biz</td>\n",
       "      <td>2051-10-05</td>\n",
       "      <td>2002-01-12</td>\n",
       "      <td>0926 Baird Roads, West Natalie, WV 81710</td>\n",
       "      <td>Professor Emeritus</td>\n",
       "      <td>6'1\"</td>\n",
       "      <td>Sierra</td>\n",
       "      <td>Turner</td>\n",
       "      <td>380</td>\n",
       "      <td>1951</td>\n",
       "      <td>73</td>\n",
       "      <td>noble.biz</td>\n",
       "      <td>-49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lydia Wood</td>\n",
       "      <td>(460)079-6057x24612</td>\n",
       "      <td>ryan36@baker-brown.com</td>\n",
       "      <td>2043-08-08</td>\n",
       "      <td>2010-02-27</td>\n",
       "      <td>9716 Samuel Ports\\nSouth Angel, NC 85005</td>\n",
       "      <td>Sports coach</td>\n",
       "      <td>5'4\"</td>\n",
       "      <td>Lydia</td>\n",
       "      <td>Wood</td>\n",
       "      <td>460</td>\n",
       "      <td>1943</td>\n",
       "      <td>64</td>\n",
       "      <td>baker-brown.com</td>\n",
       "      <td>-33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sherri Smith</td>\n",
       "      <td>171-311-9706x8273</td>\n",
       "      <td>patriciajohnson@vega.com</td>\n",
       "      <td>2071-04-09</td>\n",
       "      <td>2021-12-02</td>\n",
       "      <td>53805 Mandy Curve\\nSouth Courtneyport, IL 77108</td>\n",
       "      <td>Glass blower/designer</td>\n",
       "      <td>5'9\"</td>\n",
       "      <td>Sherri</td>\n",
       "      <td>Smith</td>\n",
       "      <td>171</td>\n",
       "      <td>1971</td>\n",
       "      <td>69</td>\n",
       "      <td>vega.com</td>\n",
       "      <td>-49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jeremy Owens</td>\n",
       "      <td>508-429-8841</td>\n",
       "      <td>marissasmith_@hotmail.com</td>\n",
       "      <td>2056-08-12</td>\n",
       "      <td>2002-04-17</td>\n",
       "      <td>14815 Kevin Plains\\nNorth Andremouth, WV 60941</td>\n",
       "      <td>Production assistant, television</td>\n",
       "      <td>5'0\"</td>\n",
       "      <td>Jeremy</td>\n",
       "      <td>Owens</td>\n",
       "      <td>508</td>\n",
       "      <td>1956</td>\n",
       "      <td>60</td>\n",
       "      <td>hotmail.com</td>\n",
       "      <td>-54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name         phone_number              email_address  birthdate  \\\n",
       "0   Ryan Wilkins         851-082-4165    vasquezdawn@hotmail.com 2059-02-19   \n",
       "1  Sierra Turner         380-360-2156      carloswoods@noble.biz 2051-10-05   \n",
       "2     Lydia Wood  (460)079-6057x24612     ryan36@baker-brown.com 2043-08-08   \n",
       "3   Sherri Smith    171-311-9706x8273   patriciajohnson@vega.com 2071-04-09   \n",
       "4   Jeremy Owens         508-429-8841  marissasmith_@hotmail.com 2056-08-12   \n",
       "\n",
       "   startdate                                  mailing_address  \\\n",
       "0 2007-11-11       08906 Adam Avenue\\nPort Victoria, MN 71782   \n",
       "1 2002-01-12         0926 Baird Roads, West Natalie, WV 81710   \n",
       "2 2010-02-27         9716 Samuel Ports\\nSouth Angel, NC 85005   \n",
       "3 2021-12-02  53805 Mandy Curve\\nSouth Courtneyport, IL 77108   \n",
       "4 2002-04-17   14815 Kevin Plains\\nNorth Andremouth, WV 60941   \n",
       "\n",
       "                                  job height first_name last_name area_code  \\\n",
       "0  Teacher, special educational needs   6'2\"       Ryan   Wilkins       851   \n",
       "1                  Professor Emeritus   6'1\"     Sierra    Turner       380   \n",
       "2                        Sports coach   5'4\"      Lydia      Wood       460   \n",
       "3               Glass blower/designer   5'9\"     Sherri     Smith       171   \n",
       "4    Production assistant, television   5'0\"     Jeremy     Owens       508   \n",
       "\n",
       "  birthyear  ht_in           domain  age  \n",
       "0      1959     74      hotmail.com  -51  \n",
       "1      1951     73        noble.biz  -49  \n",
       "2      1943     64  baker-brown.com  -33  \n",
       "3      1971     69         vega.com  -49  \n",
       "4      1956     60      hotmail.com  -54  "
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['birthdate'] = pd.to_datetime(df['birthdate'], format='%m/%d/%y', errors='coerce')\n",
    "\n",
    "def apply_pivot_year(date, pivot_year=50):\n",
    "    date = pd.to_datetime(date, format='%m/%d/%y')\n",
    "    year = date.year\n",
    "    if year < 2000:\n",
    "        date = date + pd.DateOffset(years=100) if year % 100 >= pivot_year else date\n",
    "    return date\n",
    "\n",
    "df['birthdate'] = df['birthdate'].apply(apply_pivot_year)\n",
    "df['startdate'] = df['startdate'].apply(apply_pivot_year)\n",
    "\n",
    "df['age'] = (df['startdate'] - df['birthdate']).dt.days\n",
    "df['age'] = (df['age'] / 365).astype(int)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>phone_number</th>\n",
       "      <th>email_address</th>\n",
       "      <th>birthdate</th>\n",
       "      <th>startdate</th>\n",
       "      <th>mailing_address</th>\n",
       "      <th>job</th>\n",
       "      <th>height</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>area_code</th>\n",
       "      <th>birthyear</th>\n",
       "      <th>ht_in</th>\n",
       "      <th>domain</th>\n",
       "      <th>age</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zipcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ryan Wilkins</td>\n",
       "      <td>851-082-4165</td>\n",
       "      <td>vasquezdawn@hotmail.com</td>\n",
       "      <td>2059-02-19</td>\n",
       "      <td>2007-11-11</td>\n",
       "      <td>08906 Adam Avenue\\nPort Victoria, MN 71782</td>\n",
       "      <td>Teacher, special educational needs</td>\n",
       "      <td>6'2\"</td>\n",
       "      <td>Ryan</td>\n",
       "      <td>Wilkins</td>\n",
       "      <td>851</td>\n",
       "      <td>1959</td>\n",
       "      <td>74</td>\n",
       "      <td>hotmail.com</td>\n",
       "      <td>-51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08906 Adam Avenue</td>\n",
       "      <td>71782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sierra Turner</td>\n",
       "      <td>380-360-2156</td>\n",
       "      <td>carloswoods@noble.biz</td>\n",
       "      <td>2051-10-05</td>\n",
       "      <td>2002-01-12</td>\n",
       "      <td>0926 Baird Roads, West Natalie, WV 81710</td>\n",
       "      <td>Professor Emeritus</td>\n",
       "      <td>6'1\"</td>\n",
       "      <td>Sierra</td>\n",
       "      <td>Turner</td>\n",
       "      <td>380</td>\n",
       "      <td>1951</td>\n",
       "      <td>73</td>\n",
       "      <td>noble.biz</td>\n",
       "      <td>-49</td>\n",
       "      <td>West Natalie</td>\n",
       "      <td>WV 81710</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lydia Wood</td>\n",
       "      <td>(460)079-6057x24612</td>\n",
       "      <td>ryan36@baker-brown.com</td>\n",
       "      <td>2043-08-08</td>\n",
       "      <td>2010-02-27</td>\n",
       "      <td>9716 Samuel Ports\\nSouth Angel, NC 85005</td>\n",
       "      <td>Sports coach</td>\n",
       "      <td>5'4\"</td>\n",
       "      <td>Lydia</td>\n",
       "      <td>Wood</td>\n",
       "      <td>460</td>\n",
       "      <td>1943</td>\n",
       "      <td>64</td>\n",
       "      <td>baker-brown.com</td>\n",
       "      <td>-33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9716 Samuel Ports</td>\n",
       "      <td>85005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sherri Smith</td>\n",
       "      <td>171-311-9706x8273</td>\n",
       "      <td>patriciajohnson@vega.com</td>\n",
       "      <td>2071-04-09</td>\n",
       "      <td>2021-12-02</td>\n",
       "      <td>53805 Mandy Curve\\nSouth Courtneyport, IL 77108</td>\n",
       "      <td>Glass blower/designer</td>\n",
       "      <td>5'9\"</td>\n",
       "      <td>Sherri</td>\n",
       "      <td>Smith</td>\n",
       "      <td>171</td>\n",
       "      <td>1971</td>\n",
       "      <td>69</td>\n",
       "      <td>vega.com</td>\n",
       "      <td>-49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53805 Mandy Curve</td>\n",
       "      <td>77108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jeremy Owens</td>\n",
       "      <td>508-429-8841</td>\n",
       "      <td>marissasmith_@hotmail.com</td>\n",
       "      <td>2056-08-12</td>\n",
       "      <td>2002-04-17</td>\n",
       "      <td>14815 Kevin Plains\\nNorth Andremouth, WV 60941</td>\n",
       "      <td>Production assistant, television</td>\n",
       "      <td>5'0\"</td>\n",
       "      <td>Jeremy</td>\n",
       "      <td>Owens</td>\n",
       "      <td>508</td>\n",
       "      <td>1956</td>\n",
       "      <td>60</td>\n",
       "      <td>hotmail.com</td>\n",
       "      <td>-54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14815 Kevin Plains</td>\n",
       "      <td>60941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name         phone_number              email_address  birthdate  \\\n",
       "0   Ryan Wilkins         851-082-4165    vasquezdawn@hotmail.com 2059-02-19   \n",
       "1  Sierra Turner         380-360-2156      carloswoods@noble.biz 2051-10-05   \n",
       "2     Lydia Wood  (460)079-6057x24612     ryan36@baker-brown.com 2043-08-08   \n",
       "3   Sherri Smith    171-311-9706x8273   patriciajohnson@vega.com 2071-04-09   \n",
       "4   Jeremy Owens         508-429-8841  marissasmith_@hotmail.com 2056-08-12   \n",
       "\n",
       "   startdate                                  mailing_address  \\\n",
       "0 2007-11-11       08906 Adam Avenue\\nPort Victoria, MN 71782   \n",
       "1 2002-01-12         0926 Baird Roads, West Natalie, WV 81710   \n",
       "2 2010-02-27         9716 Samuel Ports\\nSouth Angel, NC 85005   \n",
       "3 2021-12-02  53805 Mandy Curve\\nSouth Courtneyport, IL 77108   \n",
       "4 2002-04-17   14815 Kevin Plains\\nNorth Andremouth, WV 60941   \n",
       "\n",
       "                                  job height first_name last_name area_code  \\\n",
       "0  Teacher, special educational needs   6'2\"       Ryan   Wilkins       851   \n",
       "1                  Professor Emeritus   6'1\"     Sierra    Turner       380   \n",
       "2                        Sports coach   5'4\"      Lydia      Wood       460   \n",
       "3               Glass blower/designer   5'9\"     Sherri     Smith       171   \n",
       "4    Production assistant, television   5'0\"     Jeremy     Owens       508   \n",
       "\n",
       "  birthyear  ht_in           domain  age          city               state  \\\n",
       "0      1959     74      hotmail.com  -51           NaN   08906 Adam Avenue   \n",
       "1      1951     73        noble.biz  -49  West Natalie            WV 81710   \n",
       "2      1943     64  baker-brown.com  -33           NaN   9716 Samuel Ports   \n",
       "3      1971     69         vega.com  -49           NaN   53805 Mandy Curve   \n",
       "4      1956     60      hotmail.com  -54           NaN  14815 Kevin Plains   \n",
       "\n",
       "  zipcode  \n",
       "0   71782  \n",
       "1     NaN  \n",
       "2   85005  \n",
       "3   77108  \n",
       "4   60941  "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "address_lines = df['mailing_address'].str.split('\\n')\n",
    "city_state = address_lines.str[0].str.split(', ')\n",
    "df['city'] = city_state.str[-2]\n",
    "df['state'] = city_state.str[-1]\n",
    "\n",
    "df['zipcode'] = address_lines.str[1].str.extract(r'(\\d+)$')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>area_code</th>\n",
       "      <th>birthyear</th>\n",
       "      <th>ht_in</th>\n",
       "      <th>domain</th>\n",
       "      <th>age</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zipcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ryan</td>\n",
       "      <td>Wilkins</td>\n",
       "      <td>851</td>\n",
       "      <td>1959</td>\n",
       "      <td>74</td>\n",
       "      <td>hotmail.com</td>\n",
       "      <td>-51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08906 Adam Avenue</td>\n",
       "      <td>71782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sierra</td>\n",
       "      <td>Turner</td>\n",
       "      <td>380</td>\n",
       "      <td>1951</td>\n",
       "      <td>73</td>\n",
       "      <td>noble.biz</td>\n",
       "      <td>-49</td>\n",
       "      <td>West Natalie</td>\n",
       "      <td>WV 81710</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lydia</td>\n",
       "      <td>Wood</td>\n",
       "      <td>460</td>\n",
       "      <td>1943</td>\n",
       "      <td>64</td>\n",
       "      <td>baker-brown.com</td>\n",
       "      <td>-33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9716 Samuel Ports</td>\n",
       "      <td>85005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sherri</td>\n",
       "      <td>Smith</td>\n",
       "      <td>171</td>\n",
       "      <td>1971</td>\n",
       "      <td>69</td>\n",
       "      <td>vega.com</td>\n",
       "      <td>-49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53805 Mandy Curve</td>\n",
       "      <td>77108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jeremy</td>\n",
       "      <td>Owens</td>\n",
       "      <td>508</td>\n",
       "      <td>1956</td>\n",
       "      <td>60</td>\n",
       "      <td>hotmail.com</td>\n",
       "      <td>-54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14815 Kevin Plains</td>\n",
       "      <td>60941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Angel</td>\n",
       "      <td>Graves</td>\n",
       "      <td>531</td>\n",
       "      <td>1970</td>\n",
       "      <td>73</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>-58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58259 Brandon Street Suite 057</td>\n",
       "      <td>91583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Michael</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>082</td>\n",
       "      <td>1949</td>\n",
       "      <td>74</td>\n",
       "      <td>hotmail.com</td>\n",
       "      <td>49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>988 Debbie Viaduct</td>\n",
       "      <td>79538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rebecca</td>\n",
       "      <td>Morrison</td>\n",
       "      <td>315</td>\n",
       "      <td>1978</td>\n",
       "      <td>70</td>\n",
       "      <td>yahoo.com</td>\n",
       "      <td>-69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>09249 Vincent Wall</td>\n",
       "      <td>99317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jeffrey</td>\n",
       "      <td>Riley</td>\n",
       "      <td>520</td>\n",
       "      <td>1944</td>\n",
       "      <td>67</td>\n",
       "      <td>robinson.net</td>\n",
       "      <td>-36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7270 Hernandez Plain</td>\n",
       "      <td>04552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tiffany</td>\n",
       "      <td>Vincent</td>\n",
       "      <td>606</td>\n",
       "      <td>1972</td>\n",
       "      <td>63</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>-70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>304 Stephanie Trafficway Suite 451</td>\n",
       "      <td>61088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Alison</td>\n",
       "      <td>Herring</td>\n",
       "      <td>227</td>\n",
       "      <td>1974</td>\n",
       "      <td>64</td>\n",
       "      <td>yahoo.com</td>\n",
       "      <td>-66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4000 Wendy Bridge Suite 220</td>\n",
       "      <td>98652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Kimberly</td>\n",
       "      <td>Peters</td>\n",
       "      <td>393</td>\n",
       "      <td>1943</td>\n",
       "      <td>69</td>\n",
       "      <td>yahoo.com</td>\n",
       "      <td>-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86552 Andre Island</td>\n",
       "      <td>30674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Thomas</td>\n",
       "      <td>Jones</td>\n",
       "      <td>705</td>\n",
       "      <td>1966</td>\n",
       "      <td>66</td>\n",
       "      <td>hotmail.com</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7580 Fields Fort</td>\n",
       "      <td>68457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Emily</td>\n",
       "      <td>Gilbert</td>\n",
       "      <td>517</td>\n",
       "      <td>1959</td>\n",
       "      <td>69</td>\n",
       "      <td>strong.com</td>\n",
       "      <td>-49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>688 Hubbard Gardens</td>\n",
       "      <td>35383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Michael</td>\n",
       "      <td>Baker</td>\n",
       "      <td>068</td>\n",
       "      <td>1982</td>\n",
       "      <td>73</td>\n",
       "      <td>ortiz.biz</td>\n",
       "      <td>-70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>889 Angela Radial Suite 285</td>\n",
       "      <td>67527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Jacob</td>\n",
       "      <td>Tucker</td>\n",
       "      <td>766</td>\n",
       "      <td>1969</td>\n",
       "      <td>69</td>\n",
       "      <td>clark.com</td>\n",
       "      <td>-54</td>\n",
       "      <td>Kevinberg</td>\n",
       "      <td>FL 91818</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Nicole</td>\n",
       "      <td>Hardin</td>\n",
       "      <td>426</td>\n",
       "      <td>1968</td>\n",
       "      <td>67</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>307 Matthew Plaza</td>\n",
       "      <td>40093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Kevin</td>\n",
       "      <td>Hutchinson</td>\n",
       "      <td>823</td>\n",
       "      <td>1977</td>\n",
       "      <td>61</td>\n",
       "      <td>yahoo.com</td>\n",
       "      <td>-59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>278 Harris Shoal</td>\n",
       "      <td>54411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Ashley</td>\n",
       "      <td>Brown</td>\n",
       "      <td>926</td>\n",
       "      <td>1949</td>\n",
       "      <td>65</td>\n",
       "      <td>yahoo.com</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>834 Rachel Station</td>\n",
       "      <td>35501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Julie</td>\n",
       "      <td>Alvarez</td>\n",
       "      <td>416</td>\n",
       "      <td>1959</td>\n",
       "      <td>59</td>\n",
       "      <td>yahoo.com</td>\n",
       "      <td>-51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1595 Julie Court</td>\n",
       "      <td>65311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   first_name   last_name area_code birthyear  ht_in           domain  age  \\\n",
       "0        Ryan     Wilkins       851      1959     74      hotmail.com  -51   \n",
       "1      Sierra      Turner       380      1951     73        noble.biz  -49   \n",
       "2       Lydia        Wood       460      1943     64  baker-brown.com  -33   \n",
       "3      Sherri       Smith       171      1971     69         vega.com  -49   \n",
       "4      Jeremy       Owens       508      1956     60      hotmail.com  -54   \n",
       "5       Angel      Graves       531      1970     73        gmail.com  -58   \n",
       "6     Michael     Johnson       082      1949     74      hotmail.com   49   \n",
       "7     Rebecca    Morrison       315      1978     70        yahoo.com  -69   \n",
       "8     Jeffrey       Riley       520      1944     67     robinson.net  -36   \n",
       "9     Tiffany     Vincent       606      1972     63        gmail.com  -70   \n",
       "10     Alison     Herring       227      1974     64        yahoo.com  -66   \n",
       "11   Kimberly      Peters       393      1943     69        yahoo.com  -23   \n",
       "12     Thomas       Jones       705      1966     66      hotmail.com   32   \n",
       "13      Emily     Gilbert       517      1959     69       strong.com  -49   \n",
       "14    Michael       Baker       068      1982     73        ortiz.biz  -70   \n",
       "15      Jacob      Tucker       766      1969     69        clark.com  -54   \n",
       "16     Nicole      Hardin       426      1968     67        gmail.com   26   \n",
       "17      Kevin  Hutchinson       823      1977     61        yahoo.com  -59   \n",
       "18     Ashley       Brown       926      1949     65        yahoo.com   50   \n",
       "19      Julie     Alvarez       416      1959     59        yahoo.com  -51   \n",
       "\n",
       "            city                               state zipcode  \n",
       "0            NaN                   08906 Adam Avenue   71782  \n",
       "1   West Natalie                            WV 81710     NaN  \n",
       "2            NaN                   9716 Samuel Ports   85005  \n",
       "3            NaN                   53805 Mandy Curve   77108  \n",
       "4            NaN                  14815 Kevin Plains   60941  \n",
       "5            NaN      58259 Brandon Street Suite 057   91583  \n",
       "6            NaN                  988 Debbie Viaduct   79538  \n",
       "7            NaN                  09249 Vincent Wall   99317  \n",
       "8            NaN                7270 Hernandez Plain   04552  \n",
       "9            NaN  304 Stephanie Trafficway Suite 451   61088  \n",
       "10           NaN         4000 Wendy Bridge Suite 220   98652  \n",
       "11           NaN                  86552 Andre Island   30674  \n",
       "12           NaN                    7580 Fields Fort   68457  \n",
       "13           NaN                 688 Hubbard Gardens   35383  \n",
       "14           NaN         889 Angela Radial Suite 285   67527  \n",
       "15     Kevinberg                            FL 91818     NaN  \n",
       "16           NaN                   307 Matthew Plaza   40093  \n",
       "17           NaN                    278 Harris Shoal   54411  \n",
       "18           NaN                  834 Rachel Station   35501  \n",
       "19           NaN                    1595 Julie Court   65311  "
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns = ['name', 'phone_number', 'email_address', 'birthdate', 'startdate', 'mailing_address', 'job', 'height'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('employee_cleaned.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     YEAR  MONTH METRIC    d1   d10   d11   d12   d13   d14   d15  ...  \\\n",
      "0    2006      1   PRCP   0.3   0.0   0.1   0.0   0.0   0.0   0.2  ...   \n",
      "1    2006      1   TMAX  32.0  44.0  45.0  27.0  47.0  43.0  34.0  ...   \n",
      "2    2006      1   TMIN  21.0  20.0  24.0  14.0  16.0  29.0   9.0  ...   \n",
      "3    2006      2   PRCP   0.2   0.1   0.0   0.0   0.0   0.0   0.2  ...   \n",
      "4    2006      2   TMAX  33.0  27.0  31.0  43.0  37.0  36.0  32.0  ...   \n",
      "..    ...    ...    ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
      "637  2023      9   TMAX  66.0  66.0  67.0  64.0  59.0  62.0  64.0  ...   \n",
      "638  2023      9   TMIN  49.0  46.0  45.0  44.0  42.0  42.0  43.0  ...   \n",
      "639  2023     10   PRCP   0.4   0.0   0.3   0.1   0.1   0.0   0.0  ...   \n",
      "640  2023     10   TMAX  52.0  62.0  50.0  37.0  44.0  54.0  61.0  ...   \n",
      "641  2023     10   TMIN  36.0  43.0  29.0  29.0  31.0  31.0  39.0  ...   \n",
      "\n",
      "        d29    d3     d30     d31    d4    d5    d6    d7    d8    d9  \n",
      "0       0.0   2.1     0.2     0.3   0.0   0.0   0.0   0.0   0.1   0.2  \n",
      "1      27.0  34.0    42.0    34.0  30.0  47.0  57.0  48.0  30.0  33.0  \n",
      "2      20.0  21.0    24.0    20.0  17.0  17.0  33.0  30.0  11.0   8.0  \n",
      "3    9999.0   0.0  9999.0  9999.0   0.1   0.0   0.1   0.0   0.1   0.0  \n",
      "4    9999.0  31.0  9999.0  9999.0  44.0  26.0  35.0  45.0  51.0  45.0  \n",
      "..      ...   ...     ...     ...   ...   ...   ...   ...   ...   ...  \n",
      "637    65.0  65.0    60.0  9999.0  52.0  63.0  65.0  68.0  69.0  72.0  \n",
      "638    44.0  44.0    42.0  9999.0  39.0  38.0  46.0  44.0  47.0  47.0  \n",
      "639  9999.0   0.1  9999.0  9999.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "640  9999.0  43.0  9999.0  9999.0  52.0  57.0  60.0  63.0  65.0  66.0  \n",
      "641  9999.0  34.0  9999.0  9999.0  35.0  35.0  40.0  40.0  41.0  41.0  \n",
      "\n",
      "[642 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "url = 'https://github.com/esnt/Data/raw/main/MessyData/messy_weather.csv'\n",
    "weather = pd.read_csv(url)\n",
    "\n",
    "print(weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   YEAR  MONTH    d1   d10   d11   d12   d13   d14   d15  \\\n",
      "date       METRIC                                                          \n",
      "2006-01-01 PRCP    2006      1   0.3   0.0   0.1   0.0   0.0   0.0   0.2   \n",
      "           TMAX    2006      1  32.0  44.0  45.0  27.0  47.0  43.0  34.0   \n",
      "           TMIN    2006      1  21.0  20.0  24.0  14.0  16.0  29.0   9.0   \n",
      "2006-02-01 PRCP    2006      2   0.2   0.1   0.0   0.0   0.0   0.0   0.2   \n",
      "           TMAX    2006      2  33.0  27.0  31.0  43.0  37.0  36.0  32.0   \n",
      "...                 ...    ...   ...   ...   ...   ...   ...   ...   ...   \n",
      "2023-09-01 TMAX    2023      9  66.0  66.0  67.0  64.0  59.0  62.0  64.0   \n",
      "           TMIN    2023      9  49.0  46.0  45.0  44.0  42.0  42.0  43.0   \n",
      "2023-10-01 PRCP    2023     10   0.4   0.0   0.3   0.1   0.1   0.0   0.0   \n",
      "           TMAX    2023     10  52.0  62.0  50.0  37.0  44.0  54.0  61.0   \n",
      "           TMIN    2023     10  36.0  43.0  29.0  29.0  31.0  31.0  39.0   \n",
      "\n",
      "                    d16  ...     d29    d3     d30     d31    d4    d5    d6  \\\n",
      "date       METRIC        ...                                                   \n",
      "2006-01-01 PRCP     0.2  ...     0.0   2.1     0.2     0.3   0.0   0.0   0.0   \n",
      "           TMAX    25.0  ...    27.0  34.0    42.0    34.0  30.0  47.0  57.0   \n",
      "           TMIN     4.0  ...    20.0  21.0    24.0    20.0  17.0  17.0  33.0   \n",
      "2006-02-01 PRCP     0.0  ...  9999.0   0.0  9999.0  9999.0   0.1   0.0   0.1   \n",
      "           TMAX    20.0  ...  9999.0  31.0  9999.0  9999.0  44.0  26.0  35.0   \n",
      "...                 ...  ...     ...   ...     ...     ...   ...   ...   ...   \n",
      "2023-09-01 TMAX    66.0  ...    65.0  65.0    60.0  9999.0  52.0  63.0  65.0   \n",
      "           TMIN    42.0  ...    44.0  44.0    42.0  9999.0  39.0  38.0  46.0   \n",
      "2023-10-01 PRCP     0.0  ...  9999.0   0.1  9999.0  9999.0   0.0   0.0   0.0   \n",
      "           TMAX    65.0  ...  9999.0  43.0  9999.0  9999.0  52.0  57.0  60.0   \n",
      "           TMIN    43.0  ...  9999.0  34.0  9999.0  9999.0  35.0  35.0  40.0   \n",
      "\n",
      "                     d7    d8    d9  \n",
      "date       METRIC                    \n",
      "2006-01-01 PRCP     0.0   0.1   0.2  \n",
      "           TMAX    48.0  30.0  33.0  \n",
      "           TMIN    30.0  11.0   8.0  \n",
      "2006-02-01 PRCP     0.0   0.1   0.0  \n",
      "           TMAX    45.0  51.0  45.0  \n",
      "...                 ...   ...   ...  \n",
      "2023-09-01 TMAX    68.0  69.0  72.0  \n",
      "           TMIN    44.0  47.0  47.0  \n",
      "2023-10-01 PRCP     0.0   0.0   0.0  \n",
      "           TMAX    63.0  65.0  66.0  \n",
      "           TMIN    40.0  41.0  41.0  \n",
      "\n",
      "[642 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "weather['date'] = pd.to_datetime(weather['YEAR'].astype(str) + '-' + weather['MONTH'].astype(str), format='%Y-%m')\n",
    "weather = weather.set_index(['date', 'METRIC'])\n",
    "print(weather)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = weather.replace(9999, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>d1</th>\n",
       "      <th>d10</th>\n",
       "      <th>d11</th>\n",
       "      <th>d12</th>\n",
       "      <th>d13</th>\n",
       "      <th>d14</th>\n",
       "      <th>d15</th>\n",
       "      <th>d16</th>\n",
       "      <th>...</th>\n",
       "      <th>d29</th>\n",
       "      <th>d3</th>\n",
       "      <th>d30</th>\n",
       "      <th>d31</th>\n",
       "      <th>d4</th>\n",
       "      <th>d5</th>\n",
       "      <th>d6</th>\n",
       "      <th>d7</th>\n",
       "      <th>d8</th>\n",
       "      <th>d9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>METRIC</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2006-01-01</th>\n",
       "      <th>PRCP</th>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TMAX</th>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TMIN</th>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2006-02-01</th>\n",
       "      <th>PRCP</th>\n",
       "      <td>2006</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TMAX</th>\n",
       "      <td>2006</td>\n",
       "      <td>2</td>\n",
       "      <td>33.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2023-09-01</th>\n",
       "      <th>TMAX</th>\n",
       "      <td>2023</td>\n",
       "      <td>9</td>\n",
       "      <td>66.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>...</td>\n",
       "      <td>65.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TMIN</th>\n",
       "      <td>2023</td>\n",
       "      <td>9</td>\n",
       "      <td>49.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2023-10-01</th>\n",
       "      <th>PRCP</th>\n",
       "      <td>2023</td>\n",
       "      <td>10</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TMAX</th>\n",
       "      <td>2023</td>\n",
       "      <td>10</td>\n",
       "      <td>52.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TMIN</th>\n",
       "      <td>2023</td>\n",
       "      <td>10</td>\n",
       "      <td>36.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>642 rows  33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   YEAR  MONTH    d1   d10   d11   d12   d13   d14   d15  \\\n",
       "date       METRIC                                                          \n",
       "2006-01-01 PRCP    2006      1   0.3   0.0   0.1   0.0   0.0   0.0   0.2   \n",
       "           TMAX    2006      1  32.0  44.0  45.0  27.0  47.0  43.0  34.0   \n",
       "           TMIN    2006      1  21.0  20.0  24.0  14.0  16.0  29.0   9.0   \n",
       "2006-02-01 PRCP    2006      2   0.2   0.1   0.0   0.0   0.0   0.0   0.2   \n",
       "           TMAX    2006      2  33.0  27.0  31.0  43.0  37.0  36.0  32.0   \n",
       "...                 ...    ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "2023-09-01 TMAX    2023      9  66.0  66.0  67.0  64.0  59.0  62.0  64.0   \n",
       "           TMIN    2023      9  49.0  46.0  45.0  44.0  42.0  42.0  43.0   \n",
       "2023-10-01 PRCP    2023     10   0.4   0.0   0.3   0.1   0.1   0.0   0.0   \n",
       "           TMAX    2023     10  52.0  62.0  50.0  37.0  44.0  54.0  61.0   \n",
       "           TMIN    2023     10  36.0  43.0  29.0  29.0  31.0  31.0  39.0   \n",
       "\n",
       "                    d16  ...   d29    d3   d30   d31    d4    d5    d6    d7  \\\n",
       "date       METRIC        ...                                                   \n",
       "2006-01-01 PRCP     0.2  ...   0.0   2.1   0.2   0.3   0.0   0.0   0.0   0.0   \n",
       "           TMAX    25.0  ...  27.0  34.0  42.0  34.0  30.0  47.0  57.0  48.0   \n",
       "           TMIN     4.0  ...  20.0  21.0  24.0  20.0  17.0  17.0  33.0  30.0   \n",
       "2006-02-01 PRCP     0.0  ...   NaN   0.0   NaN   NaN   0.1   0.0   0.1   0.0   \n",
       "           TMAX    20.0  ...   NaN  31.0   NaN   NaN  44.0  26.0  35.0  45.0   \n",
       "...                 ...  ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "2023-09-01 TMAX    66.0  ...  65.0  65.0  60.0   NaN  52.0  63.0  65.0  68.0   \n",
       "           TMIN    42.0  ...  44.0  44.0  42.0   NaN  39.0  38.0  46.0  44.0   \n",
       "2023-10-01 PRCP     0.0  ...   NaN   0.1   NaN   NaN   0.0   0.0   0.0   0.0   \n",
       "           TMAX    65.0  ...   NaN  43.0   NaN   NaN  52.0  57.0  60.0  63.0   \n",
       "           TMIN    43.0  ...   NaN  34.0   NaN   NaN  35.0  35.0  40.0  40.0   \n",
       "\n",
       "                     d8    d9  \n",
       "date       METRIC              \n",
       "2006-01-01 PRCP     0.1   0.2  \n",
       "           TMAX    30.0  33.0  \n",
       "           TMIN    11.0   8.0  \n",
       "2006-02-01 PRCP     0.1   0.0  \n",
       "           TMAX    51.0  45.0  \n",
       "...                 ...   ...  \n",
       "2023-09-01 TMAX    69.0  72.0  \n",
       "           TMIN    47.0  47.0  \n",
       "2023-10-01 PRCP     0.0   0.0  \n",
       "           TMAX    65.0  66.0  \n",
       "           TMIN    41.0  41.0  \n",
       "\n",
       "[642 rows x 33 columns]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather = weather[weather.index.get_level_values('METRIC').isin(['TMAX', 'TMIN', 'PRCP'])]\n",
    "weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = weather.unstack(level = 'METRIC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             date  YEAR             MONTH             d1              ...  \\\n",
      "METRIC             PRCP  TMAX  TMIN  PRCP TMAX TMIN PRCP  TMAX  TMIN  ...   \n",
      "0      2006-01-01  2006  2006  2006     1    1    1  0.3  32.0  21.0  ...   \n",
      "1      2006-02-01  2006  2006  2006     2    2    2  0.2  33.0  22.0  ...   \n",
      "2      2006-03-01  2006  2006  2006     3    3    3  0.2  38.0  20.0  ...   \n",
      "3      2006-04-01  2006  2006  2006     4    4    4  0.6  39.0  20.0  ...   \n",
      "4      2006-05-01  2006  2006  2006     5    5    5  0.0  56.0  35.0  ...   \n",
      "..            ...   ...   ...   ...   ...  ...  ...  ...   ...   ...  ...   \n",
      "209    2023-06-01  2023  2023  2023     6    6    6  0.1  61.0  43.0  ...   \n",
      "210    2023-07-01  2023  2023  2023     7    7    7  0.0  73.0  49.0  ...   \n",
      "211    2023-08-01  2023  2023  2023     8    8    8  0.2  71.0  51.0  ...   \n",
      "212    2023-09-01  2023  2023  2023     9    9    9  0.4  66.0  49.0  ...   \n",
      "213    2023-10-01  2023  2023  2023    10   10   10  0.4  52.0  36.0  ...   \n",
      "\n",
      "          d6   d7               d8               d9              \n",
      "METRIC  TMIN PRCP  TMAX  TMIN PRCP  TMAX  TMIN PRCP  TMAX  TMIN  \n",
      "0       33.0  0.0  48.0  30.0  0.1  30.0  11.0  0.2  33.0   8.0  \n",
      "1        7.0  0.0  45.0  23.0  0.1  51.0  25.0  0.0  45.0  19.0  \n",
      "2       30.0  0.3  32.0  22.0  0.1  39.0  16.0  0.2  31.0  11.0  \n",
      "3       25.0  0.3  49.0  24.0  0.1  52.0  31.0  0.0  55.0  37.0  \n",
      "4       33.0  0.0  56.0  35.0  0.0  49.0  37.0  0.0  47.0  31.0  \n",
      "..       ...  ...   ...   ...  ...   ...   ...  ...   ...   ...  \n",
      "209     45.0  0.1  63.0  44.0  0.0  62.0  42.0  0.0  61.0  42.0  \n",
      "210     53.0  0.0  74.0  52.0  0.0  74.0  49.0  0.0  77.0  51.0  \n",
      "211     50.0  0.0  70.0  50.0  0.1  64.0  47.0  0.0  69.0  44.0  \n",
      "212     46.0  0.0  68.0  44.0  0.0  69.0  47.0  0.0  72.0  47.0  \n",
      "213     40.0  0.0  63.0  40.0  0.0  65.0  41.0  0.0  66.0  41.0  \n",
      "\n",
      "[214 rows x 100 columns]\n"
     ]
    }
   ],
   "source": [
    "weather = weather.reset_index()\n",
    "print(weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.to_csv('clean_weather.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th colspan=\"3\" halign=\"left\">YEAR</th>\n",
       "      <th colspan=\"3\" halign=\"left\">MONTH</th>\n",
       "      <th colspan=\"3\" halign=\"left\">d1</th>\n",
       "      <th>...</th>\n",
       "      <th>d6</th>\n",
       "      <th colspan=\"3\" halign=\"left\">d7</th>\n",
       "      <th colspan=\"3\" halign=\"left\">d8</th>\n",
       "      <th colspan=\"3\" halign=\"left\">d9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>METRIC</th>\n",
       "      <th></th>\n",
       "      <th>PRCP</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>...</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>2006</td>\n",
       "      <td>2006</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>33.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-02-01</td>\n",
       "      <td>2006</td>\n",
       "      <td>2006</td>\n",
       "      <td>2006</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>33.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>51.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-03-01</td>\n",
       "      <td>2006</td>\n",
       "      <td>2006</td>\n",
       "      <td>2006</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>38.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-04-01</td>\n",
       "      <td>2006</td>\n",
       "      <td>2006</td>\n",
       "      <td>2006</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>39.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>49.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>52.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-05-01</td>\n",
       "      <td>2006</td>\n",
       "      <td>2006</td>\n",
       "      <td>2006</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>61.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>63.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>71.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>64.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>66.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>...</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.4</td>\n",
       "      <td>52.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214 rows  100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  YEAR             MONTH             d1              ...  \\\n",
       "METRIC             PRCP  TMAX  TMIN  PRCP TMAX TMIN PRCP  TMAX  TMIN  ...   \n",
       "0      2006-01-01  2006  2006  2006     1    1    1  0.3  32.0  21.0  ...   \n",
       "1      2006-02-01  2006  2006  2006     2    2    2  0.2  33.0  22.0  ...   \n",
       "2      2006-03-01  2006  2006  2006     3    3    3  0.2  38.0  20.0  ...   \n",
       "3      2006-04-01  2006  2006  2006     4    4    4  0.6  39.0  20.0  ...   \n",
       "4      2006-05-01  2006  2006  2006     5    5    5  0.0  56.0  35.0  ...   \n",
       "..            ...   ...   ...   ...   ...  ...  ...  ...   ...   ...  ...   \n",
       "209    2023-06-01  2023  2023  2023     6    6    6  0.1  61.0  43.0  ...   \n",
       "210    2023-07-01  2023  2023  2023     7    7    7  0.0  73.0  49.0  ...   \n",
       "211    2023-08-01  2023  2023  2023     8    8    8  0.2  71.0  51.0  ...   \n",
       "212    2023-09-01  2023  2023  2023     9    9    9  0.4  66.0  49.0  ...   \n",
       "213    2023-10-01  2023  2023  2023    10   10   10  0.4  52.0  36.0  ...   \n",
       "\n",
       "          d6   d7               d8               d9              \n",
       "METRIC  TMIN PRCP  TMAX  TMIN PRCP  TMAX  TMIN PRCP  TMAX  TMIN  \n",
       "0       33.0  0.0  48.0  30.0  0.1  30.0  11.0  0.2  33.0   8.0  \n",
       "1        7.0  0.0  45.0  23.0  0.1  51.0  25.0  0.0  45.0  19.0  \n",
       "2       30.0  0.3  32.0  22.0  0.1  39.0  16.0  0.2  31.0  11.0  \n",
       "3       25.0  0.3  49.0  24.0  0.1  52.0  31.0  0.0  55.0  37.0  \n",
       "4       33.0  0.0  56.0  35.0  0.0  49.0  37.0  0.0  47.0  31.0  \n",
       "..       ...  ...   ...   ...  ...   ...   ...  ...   ...   ...  \n",
       "209     45.0  0.1  63.0  44.0  0.0  62.0  42.0  0.0  61.0  42.0  \n",
       "210     53.0  0.0  74.0  52.0  0.0  74.0  49.0  0.0  77.0  51.0  \n",
       "211     50.0  0.0  70.0  50.0  0.1  64.0  47.0  0.0  69.0  44.0  \n",
       "212     46.0  0.0  68.0  44.0  0.0  69.0  47.0  0.0  72.0  47.0  \n",
       "213     40.0  0.0  63.0  40.0  0.0  65.0  41.0  0.0  66.0  41.0  \n",
       "\n",
       "[214 rows x 100 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rows = weather.shape[0]\n",
    "num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_mean_tmax = weather['TMAX'].mean()\n",
    "overall_mean_tmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_tmin_august_1 = weather[weather['month'] == 8][weather['day'] == 1]['TMIN'].mean()\n",
    "mean_tmin_august_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_prcp_date = weather.loc[weather['PRCP'].idxmax()]['date']\n",
    "max_prcp_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_prcp_value = weather['PRCP'].max()\n",
    "max_prcp_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['Temp_Diff'] = weather['TMAX'] - weather['TMIN']\n",
    "month_with_largest_temp_diff = weather.groupby('month')['Temp_Diff'].mean().idxmax()\n",
    "month_with_largest_temp_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          country  year g_whoregion  newrel_m014  newrel_m1519  newrel_m2024  \\\n",
      "0     Afghanistan  2013         EMR       1705.0           NaN           NaN   \n",
      "1     Afghanistan  2014         EMR       2171.0           NaN           NaN   \n",
      "2     Afghanistan  2015         EMR       2537.0           NaN           NaN   \n",
      "3     Afghanistan  2016         EMR       3248.0           NaN           NaN   \n",
      "4     Afghanistan  2017         EMR       4806.0           NaN           NaN   \n",
      "...           ...   ...         ...          ...           ...           ...   \n",
      "1715     Zimbabwe  2016         AFR        794.0           NaN           NaN   \n",
      "1716     Zimbabwe  2017         AFR        719.0           NaN           NaN   \n",
      "1717     Zimbabwe  2018         AFR        768.0           NaN           NaN   \n",
      "1718     Zimbabwe  2019         AFR        648.0         397.0         839.0   \n",
      "1719     Zimbabwe  2020         AFR        468.0         302.0         672.0   \n",
      "\n",
      "      newrel_m2534  newrel_m3544  newrel_m4554  newrel_m5564  newrel_m65  \\\n",
      "0              NaN           NaN           NaN           NaN         NaN   \n",
      "1              NaN           NaN           NaN           NaN         NaN   \n",
      "2              NaN           NaN           NaN           NaN         NaN   \n",
      "3              NaN           NaN           NaN           NaN         NaN   \n",
      "4           3127.0        2276.0        2113.0        2152.0      2207.0   \n",
      "...            ...           ...           ...           ...         ...   \n",
      "1715        4349.0        4795.0        2238.0        1121.0      1068.0   \n",
      "1716        4164.0        4876.0        2243.0        1142.0      1118.0   \n",
      "1717        3856.0        4477.0        2200.0        1189.0      1331.0   \n",
      "1718        3289.0        4147.0        2098.0         953.0       959.0   \n",
      "1719        2516.0        3092.0        1599.0         717.0       724.0   \n",
      "\n",
      "      newrel_f014  newrel_f1519  newrel_f2024  newrel_f2534  newrel_f3544  \\\n",
      "0          1749.0           NaN           NaN           NaN           NaN   \n",
      "1          2283.0           NaN           NaN           NaN           NaN   \n",
      "2          2414.0           NaN           NaN           NaN           NaN   \n",
      "3          3117.0           NaN           NaN           NaN           NaN   \n",
      "4          4926.0           NaN           NaN        4552.0        3501.0   \n",
      "...           ...           ...           ...           ...           ...   \n",
      "1715        736.0           NaN           NaN        3202.0        2793.0   \n",
      "1716        680.0           NaN           NaN        2727.0        2676.0   \n",
      "1717        749.0           NaN           NaN        2526.0        2497.0   \n",
      "1718        523.0         409.0         690.0        1779.0        2029.0   \n",
      "1719        444.0         303.0         552.0        1360.0        1396.0   \n",
      "\n",
      "      newrel_f4554  newrel_f5564  newrel_f65  \n",
      "0              NaN           NaN         NaN  \n",
      "1              NaN           NaN         NaN  \n",
      "2              NaN           NaN         NaN  \n",
      "3              NaN           NaN         NaN  \n",
      "4           3061.0        2696.0      1752.0  \n",
      "...            ...           ...         ...  \n",
      "1715        1257.0         694.0       649.0  \n",
      "1716        1236.0         734.0       717.0  \n",
      "1717        1222.0         656.0       797.0  \n",
      "1718        1004.0         592.0       652.0  \n",
      "1719         733.0         448.0       402.0  \n",
      "\n",
      "[1720 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "url = 'https://github.com/esnt/Data/raw/main/MessyData/TB2022.csv'\n",
    "TB = pd.read_csv(url)\n",
    "\n",
    "print(TB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['whoregion', 'm014', 'm1519', 'm2024', 'm2534', 'm3544', 'm4554',\n",
       "       'm5564', 'm65', 'f014', 'f1519', 'f2024', 'f2534', 'f3544', 'f4554',\n",
       "       'f5564', 'f65'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_age_number(column_name):\n",
    "    return column_name.split('_')[-1]\n",
    "\n",
    "age_numbers = TB.columns[2:].map(extract_age_number)\n",
    "age_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (17) does not match length of index (1720)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[211], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m     number \u001b[39m=\u001b[39m column_name[\u001b[39m1\u001b[39m:]  \u001b[39m# Get the rest of the characters (number)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[39mreturn\u001b[39;00m letter, number\n\u001b[0;32m----> 6\u001b[0m TB[\u001b[39m'\u001b[39m\u001b[39mletter\u001b[39m\u001b[39m'\u001b[39m], TB[\u001b[39m'\u001b[39m\u001b[39mnumber\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mTB\u001b[39m.\u001b[39mcolumns[\u001b[39m2\u001b[39m:]\u001b[39m.\u001b[39mmap(split_letter_number))\n\u001b[1;32m      7\u001b[0m TB\n",
      "File \u001b[0;32m~/anaconda3/envs/stat386/lib/python3.10/site-packages/pandas/core/frame.py:3980\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3977\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   3978\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3979\u001b[0m     \u001b[39m# set column\u001b[39;00m\n\u001b[0;32m-> 3980\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item(key, value)\n",
      "File \u001b[0;32m~/anaconda3/envs/stat386/lib/python3.10/site-packages/pandas/core/frame.py:4174\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4164\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_item\u001b[39m(\u001b[39mself\u001b[39m, key, value) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   4165\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4166\u001b[0m \u001b[39m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4167\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4172\u001b[0m \u001b[39m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4173\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4174\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sanitize_column(value)\n\u001b[1;32m   4176\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   4177\u001b[0m         key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\n\u001b[1;32m   4178\u001b[0m         \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   4179\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[1;32m   4180\u001b[0m     ):\n\u001b[1;32m   4181\u001b[0m         \u001b[39m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4182\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mis_unique \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m~/anaconda3/envs/stat386/lib/python3.10/site-packages/pandas/core/frame.py:4915\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4912\u001b[0m     \u001b[39mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n\u001b[1;32m   4914\u001b[0m \u001b[39mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 4915\u001b[0m     com\u001b[39m.\u001b[39;49mrequire_length_match(value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex)\n\u001b[1;32m   4916\u001b[0m \u001b[39mreturn\u001b[39;00m sanitize_array(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_2d\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/stat386/lib/python3.10/site-packages/pandas/core/common.py:571\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    568\u001b[0m \u001b[39mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    569\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(index):\n\u001b[0;32m--> 571\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    572\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLength of values \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    573\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(data)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    574\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdoes not match length of index \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    575\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(index)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    576\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (17) does not match length of index (1720)"
     ]
    }
   ],
   "source": [
    "def split_letter_number(column_name):\n",
    "    letter = column_name[0]  # Get the first character (letter)\n",
    "    number = column_name[1:]  # Get the rest of the characters (number)\n",
    "    return letter, number\n",
    "\n",
    "TB['letter'], TB['number'] = zip(*TB.columns[2:].map(split_letter_number))\n",
    "TB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TB = TB.rename(columns={'country': 'country', 'year': 'year', 'sex': 'sex'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TB = TB.sort_values(by=['country', 'year', 'sex', 'age'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TB['cases_ffill'] = TB.groupby(['country', 'sex', 'age'])['cases_ffill'].ffill()\n",
    "TB['cases_bwfill'] = TB.groupby(['country', 'sex', 'age'])['cases_bwfill'].bfill()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "TB.to_csv(\"TB2022_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_cases_ffill_5564 = TB[(TB['sex'] == 'f') & (TB['age'] == '55-64')]['cases_ffill'].mean()\n",
    "mean_cases_ffill_5564"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_cases_bwfill_5564 = TB[(TB['sex'] == 'f') & (TB['age'] == '55-64')]['cases_bwfill'].mean()\n",
    "mean_cases_bwfill_5564"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TB['diff_ffill_bwfill'] = TB['cases_ffill'] - TB['cases_bwfill']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_diff_combination = TB.loc[TB['diff_ffill_bwfill'].idxmax(), ['sex', 'age']]\n",
    "max_diff_combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_diff_combination = TB.loc[TB['diff_ffill_bwfill'].idxmin(), ['sex', 'age']]\n",
    "min_diff_combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2022 rank</th>\n",
       "      <th>City</th>\n",
       "      <th>State[c]</th>\n",
       "      <th>2022 estimate</th>\n",
       "      <th>2020 census</th>\n",
       "      <th>Change</th>\n",
       "      <th>2020 land area</th>\n",
       "      <th>2020 land area.1</th>\n",
       "      <th>2020 population density</th>\n",
       "      <th>2020 population density.1</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>New York[d]</td>\n",
       "      <td>New York</td>\n",
       "      <td>8335897</td>\n",
       "      <td>8804190</td>\n",
       "      <td>5.32%</td>\n",
       "      <td>300.5sqmi</td>\n",
       "      <td>778.3km2</td>\n",
       "      <td>29,298/sqmi</td>\n",
       "      <td>11,312/km2</td>\n",
       "      <td>.mw-parser-output .geo-default,.mw-parser-outp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>California</td>\n",
       "      <td>3822238</td>\n",
       "      <td>3898747</td>\n",
       "      <td>1.96%</td>\n",
       "      <td>469.5sqmi</td>\n",
       "      <td>1,216.0km2</td>\n",
       "      <td>8,304/sqmi</td>\n",
       "      <td>3,206/km2</td>\n",
       "      <td>3401N 11825W / 34.02N 118.41W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>2665039</td>\n",
       "      <td>2746388</td>\n",
       "      <td>2.96%</td>\n",
       "      <td>227.7sqmi</td>\n",
       "      <td>589.7km2</td>\n",
       "      <td>12,061/sqmi</td>\n",
       "      <td>4,657/km2</td>\n",
       "      <td>4150N 8741W / 41.84N 87.68W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Houston</td>\n",
       "      <td>Texas</td>\n",
       "      <td>2302878</td>\n",
       "      <td>2304580</td>\n",
       "      <td>0.07%</td>\n",
       "      <td>640.4sqmi</td>\n",
       "      <td>1,658.6km2</td>\n",
       "      <td>3,599/sqmi</td>\n",
       "      <td>1,390/km2</td>\n",
       "      <td>2947N 9523W / 29.79N 95.39W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>1644409</td>\n",
       "      <td>1608139</td>\n",
       "      <td>+2.26%</td>\n",
       "      <td>518.0sqmi</td>\n",
       "      <td>1,341.6km2</td>\n",
       "      <td>3,105/sqmi</td>\n",
       "      <td>1,199/km2</td>\n",
       "      <td>3334N 11205W / 33.57N 112.09W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>329</td>\n",
       "      <td>Albany</td>\n",
       "      <td>New York</td>\n",
       "      <td>100826</td>\n",
       "      <td>99224</td>\n",
       "      <td>+1.61%</td>\n",
       "      <td>21.4sqmi</td>\n",
       "      <td>55.4km2</td>\n",
       "      <td>4,637/sqmi</td>\n",
       "      <td>1,790/km2</td>\n",
       "      <td>4240N 7348W / 42.67N 73.80W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>330</td>\n",
       "      <td>Hesperia</td>\n",
       "      <td>California</td>\n",
       "      <td>100744</td>\n",
       "      <td>99818</td>\n",
       "      <td>+0.93%</td>\n",
       "      <td>72.7sqmi</td>\n",
       "      <td>188.3km2</td>\n",
       "      <td>1,373/sqmi</td>\n",
       "      <td>530/km2</td>\n",
       "      <td>3424N 11719W / 34.40N 117.32W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>331</td>\n",
       "      <td>New Bedford</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>100682</td>\n",
       "      <td>101079</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>20.0sqmi</td>\n",
       "      <td>51.8km2</td>\n",
       "      <td>5,054/sqmi</td>\n",
       "      <td>1,951/km2</td>\n",
       "      <td>4140N 7056W / 41.66N 70.94W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>332</td>\n",
       "      <td>Davenport</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>100486</td>\n",
       "      <td>101724</td>\n",
       "      <td>1.22%</td>\n",
       "      <td>63.8sqmi</td>\n",
       "      <td>165.2km2</td>\n",
       "      <td>1,594/sqmi</td>\n",
       "      <td>615/km2</td>\n",
       "      <td>4134N 9036W / 41.56N 90.60W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>333</td>\n",
       "      <td>Daly City</td>\n",
       "      <td>California</td>\n",
       "      <td>100007</td>\n",
       "      <td>104901</td>\n",
       "      <td>4.67%</td>\n",
       "      <td>7.6sqmi</td>\n",
       "      <td>19.7km2</td>\n",
       "      <td>13,803/sqmi</td>\n",
       "      <td>5,329/km2</td>\n",
       "      <td>3741N 12228W / 37.69N 122.47W</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>333 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     2022 rank         City       State[c]  2022 estimate  2020 census  \\\n",
       "0            1  New York[d]       New York        8335897      8804190   \n",
       "1            2  Los Angeles     California        3822238      3898747   \n",
       "2            3      Chicago       Illinois        2665039      2746388   \n",
       "3            4      Houston          Texas        2302878      2304580   \n",
       "4            5      Phoenix        Arizona        1644409      1608139   \n",
       "..         ...          ...            ...            ...          ...   \n",
       "328        329       Albany       New York         100826        99224   \n",
       "329        330     Hesperia     California         100744        99818   \n",
       "330        331  New Bedford  Massachusetts         100682       101079   \n",
       "331        332    Davenport           Iowa         100486       101724   \n",
       "332        333    Daly City     California         100007       104901   \n",
       "\n",
       "     Change 2020 land area 2020 land area.1 2020 population density  \\\n",
       "0    5.32%    300.5sqmi        778.3km2            29,298/sqmi   \n",
       "1    1.96%    469.5sqmi      1,216.0km2             8,304/sqmi   \n",
       "2    2.96%    227.7sqmi        589.7km2            12,061/sqmi   \n",
       "3    0.07%    640.4sqmi      1,658.6km2             3,599/sqmi   \n",
       "4    +2.26%    518.0sqmi      1,341.6km2             3,105/sqmi   \n",
       "..      ...            ...              ...                     ...   \n",
       "328  +1.61%     21.4sqmi         55.4km2             4,637/sqmi   \n",
       "329  +0.93%     72.7sqmi        188.3km2             1,373/sqmi   \n",
       "330  0.39%     20.0sqmi         51.8km2             5,054/sqmi   \n",
       "331  1.22%     63.8sqmi        165.2km2             1,594/sqmi   \n",
       "332  4.67%      7.6sqmi         19.7km2            13,803/sqmi   \n",
       "\n",
       "    2020 population density.1  \\\n",
       "0                  11,312/km2   \n",
       "1                   3,206/km2   \n",
       "2                   4,657/km2   \n",
       "3                   1,390/km2   \n",
       "4                   1,199/km2   \n",
       "..                        ...   \n",
       "328                 1,790/km2   \n",
       "329                   530/km2   \n",
       "330                 1,951/km2   \n",
       "331                   615/km2   \n",
       "332                 5,329/km2   \n",
       "\n",
       "                                              Location  \n",
       "0    .mw-parser-output .geo-default,.mw-parser-outp...  \n",
       "1                3401N 11825W / 34.02N 118.41W  \n",
       "2                  4150N 8741W / 41.84N 87.68W  \n",
       "3                  2947N 9523W / 29.79N 95.39W  \n",
       "4                3334N 11205W / 33.57N 112.09W  \n",
       "..                                                 ...  \n",
       "328                4240N 7348W / 42.67N 73.80W  \n",
       "329              3424N 11719W / 34.40N 117.32W  \n",
       "330                4140N 7056W / 41.66N 70.94W  \n",
       "331                4134N 9036W / 41.56N 90.60W  \n",
       "332              3741N 12228W / 37.69N 122.47W  \n",
       "\n",
       "[333 rows x 11 columns]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_United_States_cities_by_population'\n",
    "tables = pd.read_html(url)\n",
    "df = tables[4]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2022 rank</th>\n",
       "      <th>City</th>\n",
       "      <th>State[c]</th>\n",
       "      <th>2022 estimate</th>\n",
       "      <th>2020 census</th>\n",
       "      <th>Change</th>\n",
       "      <th>2020 land area</th>\n",
       "      <th>2020 land area.1</th>\n",
       "      <th>2020 population density</th>\n",
       "      <th>2020 population density.1</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>8335897</td>\n",
       "      <td>8804190</td>\n",
       "      <td>5.32%</td>\n",
       "      <td>300.5sqmi</td>\n",
       "      <td>778.3km2</td>\n",
       "      <td>29,298/sqmi</td>\n",
       "      <td>11,312/km2</td>\n",
       "      <td>.mw-parser-output .geo-default,.mw-parser-outp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>California</td>\n",
       "      <td>3822238</td>\n",
       "      <td>3898747</td>\n",
       "      <td>1.96%</td>\n",
       "      <td>469.5sqmi</td>\n",
       "      <td>1,216.0km2</td>\n",
       "      <td>8,304/sqmi</td>\n",
       "      <td>3,206/km2</td>\n",
       "      <td>3401N 11825W / 34.02N 118.41W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>2665039</td>\n",
       "      <td>2746388</td>\n",
       "      <td>2.96%</td>\n",
       "      <td>227.7sqmi</td>\n",
       "      <td>589.7km2</td>\n",
       "      <td>12,061/sqmi</td>\n",
       "      <td>4,657/km2</td>\n",
       "      <td>4150N 8741W / 41.84N 87.68W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Houston</td>\n",
       "      <td>Texas</td>\n",
       "      <td>2302878</td>\n",
       "      <td>2304580</td>\n",
       "      <td>0.07%</td>\n",
       "      <td>640.4sqmi</td>\n",
       "      <td>1,658.6km2</td>\n",
       "      <td>3,599/sqmi</td>\n",
       "      <td>1,390/km2</td>\n",
       "      <td>2947N 9523W / 29.79N 95.39W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>1644409</td>\n",
       "      <td>1608139</td>\n",
       "      <td>+2.26%</td>\n",
       "      <td>518.0sqmi</td>\n",
       "      <td>1,341.6km2</td>\n",
       "      <td>3,105/sqmi</td>\n",
       "      <td>1,199/km2</td>\n",
       "      <td>3334N 11205W / 33.57N 112.09W</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   2022 rank         City    State[c]  2022 estimate  2020 census  Change  \\\n",
       "0          1     New York    New York        8335897      8804190  5.32%   \n",
       "1          2  Los Angeles  California        3822238      3898747  1.96%   \n",
       "2          3      Chicago    Illinois        2665039      2746388  2.96%   \n",
       "3          4      Houston       Texas        2302878      2304580  0.07%   \n",
       "4          5      Phoenix     Arizona        1644409      1608139  +2.26%   \n",
       "\n",
       "  2020 land area 2020 land area.1 2020 population density  \\\n",
       "0    300.5sqmi        778.3km2            29,298/sqmi   \n",
       "1    469.5sqmi      1,216.0km2             8,304/sqmi   \n",
       "2    227.7sqmi        589.7km2            12,061/sqmi   \n",
       "3    640.4sqmi      1,658.6km2             3,599/sqmi   \n",
       "4    518.0sqmi      1,341.6km2             3,105/sqmi   \n",
       "\n",
       "  2020 population density.1                                           Location  \n",
       "0                11,312/km2  .mw-parser-output .geo-default,.mw-parser-outp...  \n",
       "1                 3,206/km2              3401N 11825W / 34.02N 118.41W  \n",
       "2                 4,657/km2                4150N 8741W / 41.84N 87.68W  \n",
       "3                 1,390/km2                2947N 9523W / 29.79N 95.39W  \n",
       "4                 1,199/km2              3334N 11205W / 33.57N 112.09W  "
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = df\n",
    "raw_data['City'] = raw_data['City'].apply(lambda x: re.sub(r'\\[\\w\\]', '', x))\n",
    "raw_data['State[c]'] = raw_data['State[c]'].apply(lambda x: re.sub(r'\\[\\w\\]', '', x))\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2022 rank</th>\n",
       "      <th>City</th>\n",
       "      <th>State[c]</th>\n",
       "      <th>2022 estimate</th>\n",
       "      <th>2020 census</th>\n",
       "      <th>Change</th>\n",
       "      <th>2020 land area</th>\n",
       "      <th>2020 land area.1</th>\n",
       "      <th>2020 population density</th>\n",
       "      <th>2020 population density.1</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>8335897</td>\n",
       "      <td>8804190</td>\n",
       "      <td>5.32%</td>\n",
       "      <td>300.5sqmi</td>\n",
       "      <td>778.3km2</td>\n",
       "      <td>29,298/sqmi</td>\n",
       "      <td>11,312/km2</td>\n",
       "      <td>.mw-parser-output .geo-default,.mw-parser-outp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>California</td>\n",
       "      <td>3822238</td>\n",
       "      <td>3898747</td>\n",
       "      <td>1.96%</td>\n",
       "      <td>469.5sqmi</td>\n",
       "      <td>1,216.0km2</td>\n",
       "      <td>8,304/sqmi</td>\n",
       "      <td>3,206/km2</td>\n",
       "      <td>3401N 11825W / 34.02N 118.41W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>2665039</td>\n",
       "      <td>2746388</td>\n",
       "      <td>2.96%</td>\n",
       "      <td>227.7sqmi</td>\n",
       "      <td>589.7km2</td>\n",
       "      <td>12,061/sqmi</td>\n",
       "      <td>4,657/km2</td>\n",
       "      <td>4150N 8741W / 41.84N 87.68W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Houston</td>\n",
       "      <td>Texas</td>\n",
       "      <td>2302878</td>\n",
       "      <td>2304580</td>\n",
       "      <td>0.07%</td>\n",
       "      <td>640.4sqmi</td>\n",
       "      <td>1,658.6km2</td>\n",
       "      <td>3,599/sqmi</td>\n",
       "      <td>1,390/km2</td>\n",
       "      <td>2947N 9523W / 29.79N 95.39W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>1644409</td>\n",
       "      <td>1608139</td>\n",
       "      <td>+2.26%</td>\n",
       "      <td>518.0sqmi</td>\n",
       "      <td>1,341.6km2</td>\n",
       "      <td>3,105/sqmi</td>\n",
       "      <td>1,199/km2</td>\n",
       "      <td>3334N 11205W / 33.57N 112.09W</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   2022 rank         City    State[c]  2022 estimate  2020 census  Change  \\\n",
       "0          1     New York    New York        8335897      8804190  5.32%   \n",
       "1          2  Los Angeles  California        3822238      3898747  1.96%   \n",
       "2          3      Chicago    Illinois        2665039      2746388  2.96%   \n",
       "3          4      Houston       Texas        2302878      2304580  0.07%   \n",
       "4          5      Phoenix     Arizona        1644409      1608139  +2.26%   \n",
       "\n",
       "  2020 land area 2020 land area.1 2020 population density  \\\n",
       "0    300.5sqmi        778.3km2            29,298/sqmi   \n",
       "1    469.5sqmi      1,216.0km2             8,304/sqmi   \n",
       "2    227.7sqmi        589.7km2            12,061/sqmi   \n",
       "3    640.4sqmi      1,658.6km2             3,599/sqmi   \n",
       "4    518.0sqmi      1,341.6km2             3,105/sqmi   \n",
       "\n",
       "  2020 population density.1                                           Location  \n",
       "0                11,312/km2  .mw-parser-output .geo-default,.mw-parser-outp...  \n",
       "1                 3,206/km2              3401N 11825W / 34.02N 118.41W  \n",
       "2                 4,657/km2                4150N 8741W / 41.84N 87.68W  \n",
       "3                 1,390/km2                2947N 9523W / 29.79N 95.39W  \n",
       "4                 1,199/km2              3334N 11205W / 33.57N 112.09W  "
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data['2020 census'] = raw_data['2020 census'].astype(str).str.replace(',', '')\n",
    "raw_data['2020 census'] = raw_data['2020 census'].str.extract(r'(\\d+)').astype(int)\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2022 rank</th>\n",
       "      <th>City</th>\n",
       "      <th>State[c]</th>\n",
       "      <th>2022 estimate</th>\n",
       "      <th>2020 census</th>\n",
       "      <th>Change</th>\n",
       "      <th>2020 land area</th>\n",
       "      <th>2020 land area.1</th>\n",
       "      <th>2020 population density</th>\n",
       "      <th>2020 population density.1</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>8335897</td>\n",
       "      <td>8804190</td>\n",
       "      <td>5.32%</td>\n",
       "      <td>13089780.0</td>\n",
       "      <td>778.3km2</td>\n",
       "      <td>29,298/sqmi</td>\n",
       "      <td>11,312/km2</td>\n",
       "      <td>.mw-parser-output .geo-default,.mw-parser-outp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>California</td>\n",
       "      <td>3822238</td>\n",
       "      <td>3898747</td>\n",
       "      <td>1.96%</td>\n",
       "      <td>20451420.0</td>\n",
       "      <td>1,216.0km2</td>\n",
       "      <td>8,304/sqmi</td>\n",
       "      <td>3,206/km2</td>\n",
       "      <td>3401N 11825W / 34.02N 118.41W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>2665039</td>\n",
       "      <td>2746388</td>\n",
       "      <td>2.96%</td>\n",
       "      <td>9918612.0</td>\n",
       "      <td>589.7km2</td>\n",
       "      <td>12,061/sqmi</td>\n",
       "      <td>4,657/km2</td>\n",
       "      <td>4150N 8741W / 41.84N 87.68W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Houston</td>\n",
       "      <td>Texas</td>\n",
       "      <td>2302878</td>\n",
       "      <td>2304580</td>\n",
       "      <td>0.07%</td>\n",
       "      <td>27895824.0</td>\n",
       "      <td>1,658.6km2</td>\n",
       "      <td>3,599/sqmi</td>\n",
       "      <td>1,390/km2</td>\n",
       "      <td>2947N 9523W / 29.79N 95.39W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>1644409</td>\n",
       "      <td>1608139</td>\n",
       "      <td>+2.26%</td>\n",
       "      <td>22564080.0</td>\n",
       "      <td>1,341.6km2</td>\n",
       "      <td>3,105/sqmi</td>\n",
       "      <td>1,199/km2</td>\n",
       "      <td>3334N 11205W / 33.57N 112.09W</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   2022 rank         City    State[c]  2022 estimate  2020 census  Change  \\\n",
       "0          1     New York    New York        8335897      8804190  5.32%   \n",
       "1          2  Los Angeles  California        3822238      3898747  1.96%   \n",
       "2          3      Chicago    Illinois        2665039      2746388  2.96%   \n",
       "3          4      Houston       Texas        2302878      2304580  0.07%   \n",
       "4          5      Phoenix     Arizona        1644409      1608139  +2.26%   \n",
       "\n",
       "   2020 land area 2020 land area.1 2020 population density  \\\n",
       "0      13089780.0        778.3km2            29,298/sqmi   \n",
       "1      20451420.0      1,216.0km2             8,304/sqmi   \n",
       "2       9918612.0        589.7km2            12,061/sqmi   \n",
       "3      27895824.0      1,658.6km2             3,599/sqmi   \n",
       "4      22564080.0      1,341.6km2             3,105/sqmi   \n",
       "\n",
       "  2020 population density.1                                           Location  \n",
       "0                11,312/km2  .mw-parser-output .geo-default,.mw-parser-outp...  \n",
       "1                 3,206/km2              3401N 11825W / 34.02N 118.41W  \n",
       "2                 4,657/km2                4150N 8741W / 41.84N 87.68W  \n",
       "3                 1,390/km2                2947N 9523W / 29.79N 95.39W  \n",
       "4                 1,199/km2              3334N 11205W / 33.57N 112.09W  "
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data['2020 land area'] = raw_data['2020 land area'].str.replace('sq mi', '').str.replace(',', '').str.strip()\n",
    "raw_data['2020 land area'] = raw_data['2020 land area'].str.extract(r'([\\d.]+)').astype(float) * 43560  # 1 acre = 43,560 square feet\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2022 rank</th>\n",
       "      <th>City</th>\n",
       "      <th>State[c]</th>\n",
       "      <th>2022 estimate</th>\n",
       "      <th>2020 census</th>\n",
       "      <th>Change</th>\n",
       "      <th>2020 land area</th>\n",
       "      <th>2020 land area.1</th>\n",
       "      <th>2020 population density</th>\n",
       "      <th>2020 population density.1</th>\n",
       "      <th>Location</th>\n",
       "      <th>pop_density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>8335897</td>\n",
       "      <td>8804190</td>\n",
       "      <td>5.32%</td>\n",
       "      <td>13089780.0</td>\n",
       "      <td>778.3km2</td>\n",
       "      <td>29,298/sqmi</td>\n",
       "      <td>11,312/km2</td>\n",
       "      <td>.mw-parser-output .geo-default,.mw-parser-outp...</td>\n",
       "      <td>0.672600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>California</td>\n",
       "      <td>3822238</td>\n",
       "      <td>3898747</td>\n",
       "      <td>1.96%</td>\n",
       "      <td>20451420.0</td>\n",
       "      <td>1,216.0km2</td>\n",
       "      <td>8,304/sqmi</td>\n",
       "      <td>3,206/km2</td>\n",
       "      <td>3401N 11825W / 34.02N 118.41W</td>\n",
       "      <td>0.190635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>2665039</td>\n",
       "      <td>2746388</td>\n",
       "      <td>2.96%</td>\n",
       "      <td>9918612.0</td>\n",
       "      <td>589.7km2</td>\n",
       "      <td>12,061/sqmi</td>\n",
       "      <td>4,657/km2</td>\n",
       "      <td>4150N 8741W / 41.84N 87.68W</td>\n",
       "      <td>0.276892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Houston</td>\n",
       "      <td>Texas</td>\n",
       "      <td>2302878</td>\n",
       "      <td>2304580</td>\n",
       "      <td>0.07%</td>\n",
       "      <td>27895824.0</td>\n",
       "      <td>1,658.6km2</td>\n",
       "      <td>3,599/sqmi</td>\n",
       "      <td>1,390/km2</td>\n",
       "      <td>2947N 9523W / 29.79N 95.39W</td>\n",
       "      <td>0.082614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>1644409</td>\n",
       "      <td>1608139</td>\n",
       "      <td>+2.26%</td>\n",
       "      <td>22564080.0</td>\n",
       "      <td>1,341.6km2</td>\n",
       "      <td>3,105/sqmi</td>\n",
       "      <td>1,199/km2</td>\n",
       "      <td>3334N 11205W / 33.57N 112.09W</td>\n",
       "      <td>0.071270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   2022 rank         City    State[c]  2022 estimate  2020 census  Change  \\\n",
       "0          1     New York    New York        8335897      8804190  5.32%   \n",
       "1          2  Los Angeles  California        3822238      3898747  1.96%   \n",
       "2          3      Chicago    Illinois        2665039      2746388  2.96%   \n",
       "3          4      Houston       Texas        2302878      2304580  0.07%   \n",
       "4          5      Phoenix     Arizona        1644409      1608139  +2.26%   \n",
       "\n",
       "   2020 land area 2020 land area.1 2020 population density  \\\n",
       "0      13089780.0        778.3km2            29,298/sqmi   \n",
       "1      20451420.0      1,216.0km2             8,304/sqmi   \n",
       "2       9918612.0        589.7km2            12,061/sqmi   \n",
       "3      27895824.0      1,658.6km2             3,599/sqmi   \n",
       "4      22564080.0      1,341.6km2             3,105/sqmi   \n",
       "\n",
       "  2020 population density.1  \\\n",
       "0                11,312/km2   \n",
       "1                 3,206/km2   \n",
       "2                 4,657/km2   \n",
       "3                 1,390/km2   \n",
       "4                 1,199/km2   \n",
       "\n",
       "                                            Location  pop_density  \n",
       "0  .mw-parser-output .geo-default,.mw-parser-outp...     0.672600  \n",
       "1              3401N 11825W / 34.02N 118.41W     0.190635  \n",
       "2                4150N 8741W / 41.84N 87.68W     0.276892  \n",
       "3                2947N 9523W / 29.79N 95.39W     0.082614  \n",
       "4              3334N 11205W / 33.57N 112.09W     0.071270  "
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data['pop_density'] = raw_data['2020 census'] / raw_data['2020 land area']\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2022 rank</th>\n",
       "      <th>City</th>\n",
       "      <th>State[c]</th>\n",
       "      <th>2022 estimate</th>\n",
       "      <th>2020 census</th>\n",
       "      <th>Change</th>\n",
       "      <th>2020 land area</th>\n",
       "      <th>2020 land area.1</th>\n",
       "      <th>2020 population density</th>\n",
       "      <th>2020 population density.1</th>\n",
       "      <th>Location</th>\n",
       "      <th>pop_density</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>8335897</td>\n",
       "      <td>8804190</td>\n",
       "      <td>5.32%</td>\n",
       "      <td>13089780.0</td>\n",
       "      <td>778.3km2</td>\n",
       "      <td>29,298/sqmi</td>\n",
       "      <td>11,312/km2</td>\n",
       "      <td>.mw-parser-output .geo-default,.mw-parser-outp...</td>\n",
       "      <td>0.672600</td>\n",
       "      <td>40.66</td>\n",
       "      <td>-73.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>California</td>\n",
       "      <td>3822238</td>\n",
       "      <td>3898747</td>\n",
       "      <td>1.96%</td>\n",
       "      <td>20451420.0</td>\n",
       "      <td>1,216.0km2</td>\n",
       "      <td>8,304/sqmi</td>\n",
       "      <td>3,206/km2</td>\n",
       "      <td>3401N 11825W / 34.02N 118.41W</td>\n",
       "      <td>0.190635</td>\n",
       "      <td>34.02</td>\n",
       "      <td>-118.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>2665039</td>\n",
       "      <td>2746388</td>\n",
       "      <td>2.96%</td>\n",
       "      <td>9918612.0</td>\n",
       "      <td>589.7km2</td>\n",
       "      <td>12,061/sqmi</td>\n",
       "      <td>4,657/km2</td>\n",
       "      <td>4150N 8741W / 41.84N 87.68W</td>\n",
       "      <td>0.276892</td>\n",
       "      <td>41.84</td>\n",
       "      <td>-87.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Houston</td>\n",
       "      <td>Texas</td>\n",
       "      <td>2302878</td>\n",
       "      <td>2304580</td>\n",
       "      <td>0.07%</td>\n",
       "      <td>27895824.0</td>\n",
       "      <td>1,658.6km2</td>\n",
       "      <td>3,599/sqmi</td>\n",
       "      <td>1,390/km2</td>\n",
       "      <td>2947N 9523W / 29.79N 95.39W</td>\n",
       "      <td>0.082614</td>\n",
       "      <td>29.79</td>\n",
       "      <td>-95.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>1644409</td>\n",
       "      <td>1608139</td>\n",
       "      <td>+2.26%</td>\n",
       "      <td>22564080.0</td>\n",
       "      <td>1,341.6km2</td>\n",
       "      <td>3,105/sqmi</td>\n",
       "      <td>1,199/km2</td>\n",
       "      <td>3334N 11205W / 33.57N 112.09W</td>\n",
       "      <td>0.071270</td>\n",
       "      <td>33.57</td>\n",
       "      <td>-112.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   2022 rank         City    State[c]  2022 estimate  2020 census  Change  \\\n",
       "0          1     New York    New York        8335897      8804190  5.32%   \n",
       "1          2  Los Angeles  California        3822238      3898747  1.96%   \n",
       "2          3      Chicago    Illinois        2665039      2746388  2.96%   \n",
       "3          4      Houston       Texas        2302878      2304580  0.07%   \n",
       "4          5      Phoenix     Arizona        1644409      1608139  +2.26%   \n",
       "\n",
       "   2020 land area 2020 land area.1 2020 population density  \\\n",
       "0      13089780.0        778.3km2            29,298/sqmi   \n",
       "1      20451420.0      1,216.0km2             8,304/sqmi   \n",
       "2       9918612.0        589.7km2            12,061/sqmi   \n",
       "3      27895824.0      1,658.6km2             3,599/sqmi   \n",
       "4      22564080.0      1,341.6km2             3,105/sqmi   \n",
       "\n",
       "  2020 population density.1  \\\n",
       "0                11,312/km2   \n",
       "1                 3,206/km2   \n",
       "2                 4,657/km2   \n",
       "3                 1,390/km2   \n",
       "4                 1,199/km2   \n",
       "\n",
       "                                            Location  pop_density  latitude  \\\n",
       "0  .mw-parser-output .geo-default,.mw-parser-outp...     0.672600     40.66   \n",
       "1              3401N 11825W / 34.02N 118.41W     0.190635     34.02   \n",
       "2                4150N 8741W / 41.84N 87.68W     0.276892     41.84   \n",
       "3                2947N 9523W / 29.79N 95.39W     0.082614     29.79   \n",
       "4              3334N 11205W / 33.57N 112.09W     0.071270     33.57   \n",
       "\n",
       "   longitude  \n",
       "0     -73.94  \n",
       "1    -118.41  \n",
       "2     -87.68  \n",
       "3     -95.39  \n",
       "4    -112.09  "
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords = raw_data['Location'].str.extract(r'(\\d+\\.\\d+)N (\\d+\\.\\d+)W')\n",
    "raw_data['latitude'] = coords[0].astype(float)\n",
    "raw_data['longitude'] = -coords[1].astype(float)  # West coordinates are negative\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = raw_data[['City', 'State[c]', '2020 census', '2020 land area', 'pop_density', 'longitude', 'latitude']]\n",
    "cleaned_data = cleaned_data.rename(columns={'City': 'city', 'State[c]': 'state', '2020 census': 'population', '2020 land area': 'land_area', 'pop_density': 'pop_density', 'longitude': 'longitude', 'latitude': 'latitude'})\n",
    "cleaned_data.to_csv(\"uscities.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stat386",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
